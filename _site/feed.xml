<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.9.3">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2024-01-24T20:59:05+11:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Shahid Hussain | Blog</title><subtitle>A Data Science and Mathematics blog, focusing on Machine learning algorithms.</subtitle><author><name>Shahid Hussain</name><email>shahid.hussain0120@gmail.com</email></author><entry><title type="html">Functional vs Sequetial API for Keras in less then 3 minutes</title><link href="http://localhost:4000/machine%20learning/functional-sequential-api/" rel="alternate" type="text/html" title="Functional vs Sequetial API for Keras in less then 3 minutes" /><published>2024-01-24T00:00:00+11:00</published><updated>2024-01-24T00:00:00+11:00</updated><id>http://localhost:4000/machine%20learning/functional-sequential-api</id><content type="html" xml:base="http://localhost:4000/machine%20learning/functional-sequential-api/">&lt;h1 id=&quot;functional-vs-sequetial-api-for-keras-in-less-then-3-minutes&quot;&gt;Functional vs Sequetial API for Keras in less then 3 minutes&lt;/h1&gt;

&lt;p&gt;Reading to Keras/Tensorflow documentation, it’s a little hard to understand what exactly is the difference between sequential and functional API and all other resources are too long to read, so lets simplify it!&lt;/p&gt;

&lt;p&gt;Lets talk visually:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/function_sequential_api/function_sequential_api.png&quot; alt=&quot;function_sequential_api.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The whole point of Tensorflow with Keras is to simply the process of creating neural networks so now we dont spend time on manully coding a neural network, but rather focus on improving the performance of our model. Now how exactly does Functional api improve flexibility but at the cost of complexity?&lt;/p&gt;

&lt;h2 id=&quot;sequential-api&quot;&gt;Sequential API&lt;/h2&gt;
&lt;p&gt;Sequential API’s tipically look like this:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/function_sequential_api/sequential.png&quot; alt=&quot;sequential.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Notice, although we specify the pooling dimensions and strides and other arguements within the tf.keras.layers call , we can’t input specific paramters like Z1,A1 or Z2. Importantly it all happens sequentially so the model will start from the top end go by each call one by one until the end.&lt;/p&gt;

&lt;h1 id=&quot;function-api--spot-the-difference&quot;&gt;Function API : spot the difference&lt;/h1&gt;
&lt;p&gt;Alternatively, comparing this to functional API it allows use to play around with the parameters:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/function_sequential_api/sequential.png&quot; alt=&quot;functional_api.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Notice how we adding paramters to our calls to tf.keras.layers()(Paramter) providing us flexibility to choose which parameters we want to trasnform. Note this is just one way of taking advantage of function API. Other possible options are :&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;Multiple inputs - Now we can have multiple paramters since our functional isnt called linearly&lt;/li&gt;
  &lt;li&gt;Sharing inputs - say we want Z1 to have multiple acitivations say Leaky-RelU and ReLU&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;But as you can see the possibility or errors increases since you can play around with which inputs you want where. So be careful!&lt;/p&gt;

&lt;h1 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h1&gt;

&lt;p&gt;Hopefully now you understand the difference between Sequential and Functional API!&lt;/p&gt;</content><author><name>Shahid Hussain</name><email>shahid.hussain0120@gmail.com</email></author><category term="Machine Learning" /><summary type="html">Functional vs Sequetial API for Keras in less then 3 minutes</summary></entry><entry><title type="html">My Machine Learing Mastery Roadmap</title><link href="http://localhost:4000/machine%20learning/machine-learning-curriculum/" rel="alternate" type="text/html" title="My Machine Learing Mastery Roadmap" /><published>2024-01-11T00:00:00+11:00</published><updated>2024-01-11T00:00:00+11:00</updated><id>http://localhost:4000/machine%20learning/machine-learning-curriculum</id><content type="html" xml:base="http://localhost:4000/machine%20learning/machine-learning-curriculum/">&lt;p&gt;After watching many videos and having a solid foundational of a overview of concepts 
and tool in machine learing i beleive it finally time for me to make a curriculm!&lt;/p&gt;

&lt;h2 id=&quot;hmmmhow-do-i-go-about-this&quot;&gt;Hmmm…How do i go about this?&lt;/h2&gt;

&lt;p&gt;Before asessing my weakness, what are my inspiration say is a good pathway? 
Well after watching Lex Fridman interview with Andrew Ng &lt;a href=&quot;https://www.youtube.com/watch?v=1k37OcjH7BM&amp;amp;t=1381s&quot;&gt;here!&lt;/a&gt; 
he speicficed the improtance of taking the refined coursework including ML, Deep Learning, Mlops, tensorflow certification courses then focusing
once you have taken enough courses then work on projects and reading research papers.&lt;/p&gt;

&lt;p&gt;Addtionally, Daniel Bourke, a fellow Australian has created a amazing mindmap (i love mindmaps) for a stack needed to become a ML engineer (here!)[https://whimsical.com/machine-learning-roadmap-2020-CA7f3ykvXpnJ9Az32vYXva]. The main focuses resrouces including fast.ai, CS50’s, Hnads-on Machine Learning by Aurelien Geron.&lt;/p&gt;

&lt;h2 id=&quot;focus-on-the-weakness&quot;&gt;Focus on the weakness&lt;/h2&gt;

&lt;p&gt;I beleive (currently?) Machine learning ecosystem can be broken down into the follow skills&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Mathematics&lt;/li&gt;
  &lt;li&gt;ML algorithms&lt;/li&gt;
  &lt;li&gt;MLops&lt;/li&gt;
  &lt;li&gt;Python skills&lt;/li&gt;
  &lt;li&gt;Cloud Services&lt;/li&gt;
  &lt;li&gt;SQL database&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Since i have a currenlty pursuing a Mathhematics and Marketing degree, the main focus should be builing later half. Althought i have expericnes with Cloud Services including AWS and 
SQL database i will significnatly have to improve in this area. Addtionally, my Python skills a desent but thtere is a way to go&lt;/p&gt;

&lt;h1 id=&quot;what-i-have-currently-done&quot;&gt;What i have currently done?&lt;/h1&gt;

&lt;p&gt;Well currently i have completed/doing:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;CS29 by Andrew Ng&lt;/li&gt;
  &lt;li&gt;Hands-On Machine Learning with Scikit-Learn and Tensorflow&lt;/li&gt;
  &lt;li&gt;The Hundred-page Machine Learning Book by Andriy Burkov&lt;/li&gt;
  &lt;li&gt;Deep learning Specialisation by Andrew Ng&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;the-roadmap-with-certifications&quot;&gt;The Roadmap With Certifications&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;Programming
    &lt;ul&gt;
      &lt;li&gt;“Python 3 Object-Oriented Programming” by Dusty Phillips&lt;/li&gt;
      &lt;li&gt;“Fluent Python” Book by Luciano Ramalho&lt;/li&gt;
      &lt;li&gt;“Algorithms” Princeton University&lt;/li&gt;
      &lt;li&gt;“Coding Interview University” (github)[https://github.com/jwasham/coding-interview-university]&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;ML algorithms
    &lt;ul&gt;
      &lt;li&gt;Deep Learning for Coders with fastai &amp;amp; PyTorch&lt;/li&gt;
      &lt;li&gt;Introduction to Machine Learning with Python: A Guide for Data Scientists&lt;/li&gt;
      &lt;li&gt;Neural Networks : Zero to hero by Andrej Karpathy&lt;/li&gt;
      &lt;li&gt;Recipe for training neural networks by Andrej Karpathy&lt;/li&gt;
      &lt;li&gt;Papers with Code : Most popular and Recent machine learning papers&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;MLops
    &lt;ul&gt;
      &lt;li&gt;Desigining Machine Learing Systems by Chip Huyen&lt;/li&gt;
      &lt;li&gt;Stanford’s CS 329S: Machine Learning Systems Design by Chip Huyen&lt;/li&gt;
      &lt;li&gt;Coursera’s MLOps Specialization by DeepLearning.AI&lt;/li&gt;
      &lt;li&gt;Full Stack Deep Learning&lt;/li&gt;
      &lt;li&gt;fast.ai&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Cloud
    &lt;ul&gt;
      &lt;li&gt;Microsoft Certified: Azure Fundamentals&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;SQL
    &lt;ul&gt;
      &lt;li&gt;LeetCode SQL&lt;/li&gt;
      &lt;li&gt;SQL for Data Analysis Advanced Techniques for Transforming Data into Insights&lt;/li&gt;
      &lt;li&gt;SQL Tutorial for Beginners (and Technical Interview Questions Solved) by freeCodeCamp.org&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;structure&quot;&gt;Structure&lt;/h1&gt;

&lt;p&gt;Currently since unviersity off i have a little time to concurrently complete 2 courses at the same time, the plan is i want to read for projects i want to have a project in mind work on whilst reading/watching resources. The currentl systtemiatic plan is;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Deep learning Specialisation by Andrew Ng  + Stanford’s CS 329S: Machine Learning Systems Design by Chip Huyen&lt;/li&gt;
  &lt;li&gt;Neural Networks : Zero to hero by Andrej Karpathy + Recipe for training neural networks by Andrej Karpathy&lt;/li&gt;
  &lt;li&gt;“Algorithms” Princeton University + “Fluent Python” Book by Luciano Ramalho&lt;/li&gt;
  &lt;li&gt;Full Stack Deep Learning + fast.ai&lt;/li&gt;
  &lt;li&gt;Microsoft Certified: Azure Fundamentals + SQL Tutorial for Beginners (and Technical Interview Questions Solved) by freeCodeCamp.org&lt;/li&gt;
&lt;/ol&gt;</content><author><name>Shahid Hussain</name><email>shahid.hussain0120@gmail.com</email></author><category term="Machine Learning" /><summary type="html">After watching many videos and having a solid foundational of a overview of concepts and tool in machine learing i beleive it finally time for me to make a curriculm!</summary></entry><entry><title type="html">Is it true that long-term injuries comes from prior minior injuries?</title><link href="http://localhost:4000/projects/nba-risk-injury/" rel="alternate" type="text/html" title="Is it true that long-term injuries comes from prior minior injuries?" /><published>2024-01-07T00:00:00+11:00</published><updated>2024-01-07T00:00:00+11:00</updated><id>http://localhost:4000/projects/nba-risk-injury</id><content type="html" xml:base="http://localhost:4000/projects/nba-risk-injury/">&lt;h1 id=&quot;a-lense-from-a-statistical-point-of-view-can-we-create-a-ml-model-to-predicit-the-outcomes&quot;&gt;A lense from a statistical point of view. Can we create a ML model to predicit the outcomes?&lt;/h1&gt;

&lt;h1 id=&quot;introduction&quot;&gt;Introduction&lt;/h1&gt;

&lt;p&gt;After watching sports for many years, I noticed non-contact injuries, especially in the NBA. I went on to examine it. Randomly, I clicked on a video where a popular YouTuber states, ‘Look at KD; he had an ACL injury, and before that, he had a calf strain.’ Is this really true? The YouTube channel mentioned is MPJPerformance, and the video link is &lt;a href=&quot;https://www.youtube.com/watch?v=HnPjGpcTU8A&amp;amp;t=47s.&quot;&gt;here!&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&quot;retriving-and-cleaning-the-data&quot;&gt;Retriving and Cleaning the data&lt;/h1&gt;

&lt;h2 id=&quot;firstly-getting-the-data&quot;&gt;Firstly getting the data&lt;/h2&gt;

&lt;p&gt;Luckly for me the raw data is already avaliable, big thanks to JaseZiv for the github repositry &lt;a href=&quot;https://github.com/JaseZiv/NBA_data/tree/main&quot;&gt;click here!&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;how-is-the-data-currently-structured&quot;&gt;How is the data currently structured?&lt;/h2&gt;

&lt;p&gt;the file named “nba_injuries” has webcrawled various NBA sources and the origian files follow a JSON schema as follows:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Date:&lt;/strong&gt; 1947-08-05&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Team:&lt;/strong&gt; Bombers (BAA)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Acquired:&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Relinquished:&lt;/strong&gt; Jack Underman&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Notes:&lt;/strong&gt; fractured legs (in auto accident) (out indefinitely) (date approximate)&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;creating-a-database-and-cleaning-up-the-data&quot;&gt;Creating a database and cleaning up the data&lt;/h2&gt;

&lt;p&gt;Before we can clean the data to remove duplicates and unnessary/missing inputs we first need to create a database scehema appropriate to our queries and data retrival goals.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Identify all injured playes easily&lt;/li&gt;
  &lt;li&gt;Idenify length of injury easily&lt;/li&gt;
  &lt;li&gt;Identify if this play has prior/future injury&lt;/li&gt;
  &lt;li&gt;Proximity of next injury/prior injury&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Based on these retrival goals we can take a view from a statisatical POV if “long term injuries are srouced from short term injuries”. Where we can explore…&lt;/p&gt;

&lt;p&gt;As pointed out by Chip Huyen in Chapter two of “Designing Machine Learning Systems” states the importance of Data Models “How you choose to represent data not only affects the way your systems are built, but also the problems your systems can solve”. Using this chapter as a out Chip outlines “NoSQL” to follow a strict schema, therefore for time saving we will use a “Relational Database”.&lt;/p&gt;

&lt;h1 id=&quot;lets-start-off-by-examing-it-from-a-statistics-point-of-view&quot;&gt;Let’s start off by examing it from a statistics point of view?&lt;/h1&gt;

&lt;p&gt;building the story&lt;/p&gt;</content><author><name>Shahid Hussain</name><email>shahid.hussain0120@gmail.com</email></author><category term="Projects" /><summary type="html">A lense from a statistical point of view. Can we create a ML model to predicit the outcomes?</summary></entry><entry><title type="html">Geoffrey Hinton : The godfather Deep learning?</title><link href="http://localhost:4000/inspiration/Geoffrey-Hinton/" rel="alternate" type="text/html" title="Geoffrey Hinton : The godfather Deep learning?" /><published>2024-01-05T00:00:00+11:00</published><updated>2024-01-05T00:00:00+11:00</updated><id>http://localhost:4000/inspiration/Geoffrey-Hinton</id><content type="html" xml:base="http://localhost:4000/inspiration/Geoffrey-Hinton/">&lt;p&gt;&amp;lt;!—
Interview&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;High School friedn -&amp;gt; mathematics bettwe then him states -&amp;gt; the brain uses holigram -&amp;gt; Whats a holigram? “Lashes experiement with mice where u chop bits of rats brains and where bits of brains are distrib uted over the whole brain”&lt;/li&gt;
  &lt;li&gt;university -&amp;gt; physiology + physics -&amp;gt; became a carpenter -&amp;gt; when to cmabridge to study AI -&amp;gt; where his professor just finsihed working with NN&lt;/li&gt;
  &lt;li&gt;PHD in AI -&amp;gt; couldnt get jobs in britian -&amp;gt; when to America (California)&lt;/li&gt;
  &lt;li&gt;Ron Williams, between us developed the backprop algorithm, it was mainly David Rumelhart’s idea. Paul Werbos had published it already quite a few years earlier, but nobody paid it much attention. And there were other people who’d developed very similar algorithms, it’s not clear what’s meant by backprop. But using the chain rule to get derivatives was not a novel idea. -&amp;gt; Back propigation&lt;/li&gt;
  &lt;li&gt;which one is the most exited? So I think the most beautiful one is the work I do with Terry Sejnowski on Boltzmann machines. So we discovered there was this really, really simple learning algorithm that applied to great big density connected nets where you could only see a few of the nodes. So it would learn hidden representations and it was a very simple algorithm. And it looked like the kind of thing you should be able to get in a brain because each synapse only needed to know about the behavior of the two neurons it was directly connected to.&lt;/li&gt;
  &lt;li&gt;Finish wathcing it
–!&amp;gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name>Shahid Hussain</name><email>shahid.hussain0120@gmail.com</email></author><category term="Inspiration" /><summary type="html">&amp;lt;!— Interview High School friedn -&amp;gt; mathematics bettwe then him states -&amp;gt; the brain uses holigram -&amp;gt; Whats a holigram? “Lashes experiement with mice where u chop bits of rats brains and where bits of brains are distrib uted over the whole brain” university -&amp;gt; physiology + physics -&amp;gt; became a carpenter -&amp;gt; when to cmabridge to study AI -&amp;gt; where his professor just finsihed working with NN PHD in AI -&amp;gt; couldnt get jobs in britian -&amp;gt; when to America (California) Ron Williams, between us developed the backprop algorithm, it was mainly David Rumelhart’s idea. Paul Werbos had published it already quite a few years earlier, but nobody paid it much attention. And there were other people who’d developed very similar algorithms, it’s not clear what’s meant by backprop. But using the chain rule to get derivatives was not a novel idea. -&amp;gt; Back propigation which one is the most exited? So I think the most beautiful one is the work I do with Terry Sejnowski on Boltzmann machines. So we discovered there was this really, really simple learning algorithm that applied to great big density connected nets where you could only see a few of the nodes. So it would learn hidden representations and it was a very simple algorithm. And it looked like the kind of thing you should be able to get in a brain because each synapse only needed to know about the behavior of the two neurons it was directly connected to. Finish wathcing it –!&amp;gt;</summary></entry><entry><title type="html">CS229 Review</title><link href="http://localhost:4000/review/CS290-review/" rel="alternate" type="text/html" title="CS229 Review" /><published>2024-01-01T00:00:00+11:00</published><updated>2024-01-01T00:00:00+11:00</updated><id>http://localhost:4000/review/CS290-review</id><content type="html" xml:base="http://localhost:4000/review/CS290-review/">&lt;h1 id=&quot;review-of-standford-cs229-course&quot;&gt;Review of Standford CS229 course&lt;/h1&gt;

&lt;h2 id=&quot;summary&quot;&gt;Summary&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Requires at least level 2 university mathematics. This includes an understanding of Multivariate Calculus and a bit of Linear Algebra.&lt;/li&gt;
  &lt;li&gt;Lectures provide the backbone understanding but don’t delve into the mathematics. In order to maximize the learning process, ensure completing all problem sets.&lt;/li&gt;
  &lt;li&gt;Standford students, after completing the course, create their own machine learning application. I suggest completing one as well.&lt;/li&gt;
  &lt;li&gt;Having a strong understanding of Linear Models is beneficial to understanding most concepts due to the fast pace of the course.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;comprehensive-review&quot;&gt;Comprehensive Review&lt;/h2&gt;

&lt;h1 id=&quot;introduction&quot;&gt;Introduction&lt;/h1&gt;

&lt;p&gt;After wanting to learn machine learning, I scoured the internet to find the best resources, knowing there was an unimaginable amount of books, videos, tutorials, and articles, it just left me confused and flustered!&lt;/p&gt;

&lt;p&gt;To narrow my focus, I wanted to learn from the best, so who really is the best academic in the machine learning space? Well, everyone unanimously agrees that Andrew Ng is probably the best ML teacher, and he offers amazing courses such as on Coursera. But after hearing about the world-famous CS229 as the origin of many students’ introduction to ML, I decided to take the 2018 CS229 course by Stanford.&lt;/p&gt;

&lt;h1 id=&quot;who-is-this-course-for&quot;&gt;Who is this course for?&lt;/h1&gt;

&lt;p&gt;Don’t take this course if you don’t have at least a level 2 university-level mathematics course previously. The main value in this course is it takes a dive into the mathematics behind popular machine learning algorithms. Since the focus is on mathematics, I’ve read many comments under the lecture videos stating, “Is it okay if I don’t understand the mathematics?” Well, not really, since I feel there are better resources less focused on the mathematics and provide an intuitive understanding, such as “Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow” and “The Hundred-Page Machine Learning Book by Andriy Burkov,” which just give an overview of the algorithms focusing on implementation over mathematics.&lt;/p&gt;

&lt;h1 id=&quot;is-it-okay-to-watch-the-2018-version-with-andrew-mg-over-the-new-iterations-of-the-course&quot;&gt;Is it okay to watch the 2018 version with Andrew Mg over the new iterations of the course?&lt;/h1&gt;

&lt;p&gt;Many popular machine learning algorithms have been around for decades. Since this course aims to focus on the most popular algorithms in machine learning, these algorithms have been established decades ago. Let me give you an example:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Linear Regression: Sir Francis Galton in 1895&lt;/li&gt;
  &lt;li&gt;Support Vector Machine: AT&amp;amp;T Bell Laboratories by Vladimir Vapnik with colleagues in 1993&lt;/li&gt;
  &lt;li&gt;Principal Component Analysis: Karl Pearson in 1901&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;As you can see these algorithsm have been discovered decades ago. I would recommend doing the 2018 course so you can gain a true understanding of why Andrew Ng is considered one of the best ML teachers.&lt;/p&gt;

&lt;h1 id=&quot;how-to-acess-the-other-class-material-like-problem-sets-and-lectures-notes&quot;&gt;How to acess the other class material, like problem sets and lectures notes?&lt;/h1&gt;

&lt;p&gt;Supplement with the lectures are problems seta dn lectures notes. I’v found watching #link(statques) as well as #(github)&lt;/p&gt;

&lt;h1 id=&quot;what-to-do-next&quot;&gt;What to do next?&lt;/h1&gt;

&lt;p&gt;After completing the course, you should feel that you have a strong basic understanding of popular machine learning algorithms. It is important that you don’t just watch the lectures but also ensure you understand everything you’ve watched. Ensure you use the Feynman technique to try to explain concepts in your own words and don’t get trapped into the bubble of just watching lectures and thinking you know the concepts because when the interview comes around, how can you explain these concepts to the interviewer?&lt;/p&gt;

&lt;p&gt;Personally, I’ll be now taking the “Machine Learning Specialization” as well as creating my own scikit-learn emulation module to improve my ML and programming skills. I recommend you continue a similar path, now trying to do Kaggle problems or start.&lt;/p&gt;

&lt;h1 id=&quot;concluding&quot;&gt;Concluding&lt;/h1&gt;

&lt;p&gt;Watching CS290 has been a beatiful journey and i really appriate standford making this course acceisble to everyone if you want notes #—(notability)&lt;/p&gt;</content><author><name>Shahid Hussain</name><email>shahid.hussain0120@gmail.com</email></author><category term="Review" /><summary type="html">Review of Standford CS229 course</summary></entry><entry><title type="html">My First Post</title><link href="http://localhost:4000/miscellaneous/first-post/" rel="alternate" type="text/html" title="My First Post" /><published>2023-12-15T00:00:00+11:00</published><updated>2023-12-15T00:00:00+11:00</updated><id>http://localhost:4000/miscellaneous/first-post</id><content type="html" xml:base="http://localhost:4000/miscellaneous/first-post/">&lt;h1 id=&quot;welcome-to-my-blog&quot;&gt;Welcome to My Blog!&lt;/h1&gt;

&lt;p&gt;Welcome! This is my very first post on my new blog, and I’m thrilled to share my journey of exploration and information-sharing with fellow students like myself!&lt;/p&gt;

&lt;h1 id=&quot;most-important-question-first-so-how-did-i-get-into-machine-learning&quot;&gt;Most important question first, so how did I get into Machine Learning?&lt;/h1&gt;

&lt;p&gt;Well, I’ve always been interested in self-improvement. This interest started at a young age, focusing not only on becoming more effective in my studies but also on optimizing my mental and physical well-being. I regularly listen to inspiring figures like Andrew Huberman, Lex Friedman, and many more. More specifically, my journey into Machine Learning began when I took a course at UNSW called “Digital and Web Analytics.” One of the assessment tasks was to perform a sentiment analysis on a crisis a company had gone through.&lt;/p&gt;

&lt;p&gt;Initially confused about what “sentiment analysis” entailed, I started exploring scientific papers, attending random lectures, and kept encountering the term “Machine Learning.” Somehow, I created a sentiment analysis of public opinion on whether comments on YouTube and Twitter were positive, negative, or neutral using Natural Language Processing. I coded, but I faced one big problem—I had no idea how the sentiment analysis packages worked.&lt;/p&gt;

&lt;p&gt;Additionally, while navigating this, I was concurrently enrolled in a course on “Linear Models,” delving into topics like linear regression, which significantly sparked my interest. Unfortunately, the lectures never explained anything about what Machine Learning is! Why! Fueled by motivation to learn how exactly a machine categorizes words and wha alternative are there to linear regression, I scoured the internet to learn more, eventually leading me to discover the vast world of Machine Learning! And that’s the current journey I’m on now, and I can’t wait to learn more!&lt;/p&gt;</content><author><name>Shahid Hussain</name><email>shahid.hussain0120@gmail.com</email></author><category term="Miscellaneous" /><summary type="html">Welcome to My Blog!</summary></entry></feed>