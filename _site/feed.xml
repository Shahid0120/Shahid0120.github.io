<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.9.3">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2024-06-25T16:11:50+10:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Shahid Hussain | Blog</title><subtitle>A Data Science and Mathematics blog, focusing on Machine learning algorithms.</subtitle><author><name>Shahid Hussain</name><email>shahid.hussain0120@gmail.com</email></author><entry><title type="html">Episode Two (IBM x UNSW machine learning project) : Learning Models</title><link href="http://localhost:4000/ml/episdoe-two-datasoc-ibm/" rel="alternate" type="text/html" title="Episode Two (IBM x UNSW machine learning project) : Learning Models" /><published>2024-05-31T00:00:00+10:00</published><updated>2024-05-31T00:00:00+10:00</updated><id>http://localhost:4000/ml/episdoe-two-datasoc-ibm</id><content type="html" xml:base="http://localhost:4000/ml/episdoe-two-datasoc-ibm/"></content><author><name>Shahid Hussain</name><email>shahid.hussain0120@gmail.com</email></author><category term="ML" /><summary type="html"></summary></entry><entry><title type="html">Episode One (IBM x UNSW machine learning project) : Data Preprocessing</title><link href="http://localhost:4000/ml/episode-one-data-scoc-ibm/" rel="alternate" type="text/html" title="Episode One (IBM x UNSW machine learning project) : Data Preprocessing" /><published>2024-05-31T00:00:00+10:00</published><updated>2024-05-31T00:00:00+10:00</updated><id>http://localhost:4000/ml/episode-one-data-scoc-ibm</id><content type="html" xml:base="http://localhost:4000/ml/episode-one-data-scoc-ibm/">&lt;p&gt;Today was the first day of attending a term-long project with Data Society UNSW, in collaboration with IBM. The lecturer from Dr. Saeed Kasmani, a Senior AI engineer from IBM presented the fundamentals of data science workflow. The main premise is that throughout the term, we will try to optimize a machine learning algorithm with a dataset. During the term, an IBM machine learning engineer will teach us the fundamentals of machine learning, including data preprocessing and learning algorithms.&lt;/p&gt;

&lt;h1 id=&quot;the-client-and-objective&quot;&gt;The client and objective&lt;/h1&gt;

&lt;p&gt;Your client is a multinational real estate developer that builds residential and commercial properties 
around the world. They have a large portfolio of projects that are in development simultaneously. They 
currently have a 25% failure rate for their projects that is significantly higher than the industry 
benchmark of less than 10%. They would like to understand what the key leading indicators for project 
failure are when they are planning their projects. This will allow them to only invest capital into the best 
quality projects. They also want to know ongoing which projects are likely to fail so they can cut their 
losses and cease the projects. Secondly, the real estate developer would like to search local building 
policies to quickly find the relevant answers as they plan their developments. This could include zoning 
policies, environmental policies and development planning policies&lt;/p&gt;

&lt;h1 id=&quot;break-down-the-client-objective&quot;&gt;Break down the client objective&lt;/h1&gt;

&lt;ol&gt;
  &lt;li&gt;Improve picking projects - find the likelihood of project failure&lt;/li&gt;
  &lt;li&gt;Reduced speed to policy search&lt;/li&gt;
&lt;/ol&gt;

&lt;h1 id=&quot;weekly-project-overview&quot;&gt;Weekly project Overview&lt;/h1&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/ibm/ibm-weekly-break.png&quot; alt=&quot;weeklyoverview&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;data-preprocessing&quot;&gt;Data preprocessing&lt;/h2&gt;

&lt;p&gt;Our main objective before making any inference of learning models is to understand the fundamental question&lt;/p&gt;

&lt;h3 id=&quot;does-our-data-useful-proxy-for-understanding-our-problem&quot;&gt;Does our data useful ‘proxy’ for understanding our problem?&lt;/h3&gt;

&lt;p&gt;This is known as exploratory data analysis, for which is a process done after the data is usable.&lt;/p&gt;

&lt;h2 id=&quot;what-is-usable-data&quot;&gt;What is usable data?&lt;/h2&gt;
&lt;p&gt;Making a usable dataset is the process&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;Data Wrangling - sourcing, loading, and precleaning the 
data so we can see what it really looks like, fixing critical issues&lt;/li&gt;
  &lt;li&gt;Data profiling and cleaning - understanding the essential characteristics of the data , applying preliminary transformations to  confer context and meaning. Continuing implementing strategies for missing and invalid data (Imputations methods)&lt;/li&gt;
  &lt;li&gt;Data mugging - reshaping data to prepare it for analysis&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;One important lesson is that this is not a linear cycle, from Data Wrangling to Data mugging to learning models. It a iterative process for which we will continuously revise our data to import our analysis and learning model.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/ibm/IBM_data_cleaning_fixing.jpg&quot; alt=&quot;data-cleaning&quot; /&gt;&lt;/p&gt;

&lt;h1 id=&quot;how-to-go-about-data-cleaning-and-profiling&quot;&gt;How to go about Data Cleaning and Profiling?&lt;/h1&gt;

&lt;p&gt;After conducting basic data wrangling, you would proceed to preliminary data cleaning, including reformatting, data type conversion, and dealing with dirty data. Secondly, basic data profiling includes finding data types, data ranges (continuous), and categories. Thirdly, one of the most important parts of this stage is ‘assessing data quality’.&lt;/p&gt;

&lt;p&gt;When assessing data quality, we look at accuracy, reliability (veracity), currency, and relevance. This covers how many invalid or missing values each feature, row, or the overall dataset has, and what the effect is of throwing out or imputing the data.&lt;/p&gt;

&lt;p&gt;Remember, in learning algorithms, we assume each sample (i.e., each row) is part of some unknown distribution. That is to say, even the samples that are missing play a part. Therefore, by removing or imputing samples, we risk changing the distribution of the training set, which can result in large test errors!&lt;/p&gt;

&lt;h1 id=&quot;visualizing-data&quot;&gt;Visualizing Data&lt;/h1&gt;

&lt;p&gt;After this process is done, we are now ready to explore our data visually. Through this process, we can identify skewness, the mean, and even outliers. Graphs include scatterplots, wireframe plots, surface plots, histograms, box-whisker plots, and heat maps. After all these processes, we finally begin to understand the data and the features of each column.&lt;/p&gt;

&lt;h1 id=&quot;final-steps-before-trying-a-learning-model&quot;&gt;Final steps before trying a learning model&lt;/h1&gt;

&lt;p&gt;Yay, we are on our last step before the big one: ML algorithms! So now all data is cleaned, we have a solid grasp of the data, and we need to select which data helps us the most in categorizing/predicting our label. This involves three steps: feature engineering, feature reduction, and feature selection!&lt;/p&gt;

&lt;p&gt;Feature engineering in machine learning involves extracting useful features from the given input data, considering the target to be learned and the machine learning model used. It involves transforming data into forms that better relate to the underlying target to be learned. This includes variable transformations such as square root and Box-Cox transformations, and categorical encoding, like one-hot encoding in sk-learn.&lt;/p&gt;

&lt;p&gt;Feature reduction and selection involve reducing the number of variables. This is more commonly done under unsupervised learning using techniques such as PCA, factor analysis, and t-SNE. Amazingly, sk-learn has a whole user guide on feature selection!&lt;/p&gt;

&lt;p&gt;And there we have it! Now, we know the basic outline of data preprocessing. Just a little note: finding valuable, straight-to-the-point information on data preprocessing is extremely difficult. Some textbooks cover the basics, while others go too in-depth. There isn’t anything that’s just enough to perform a basic data science project.&lt;/p&gt;</content><author><name>Shahid Hussain</name><email>shahid.hussain0120@gmail.com</email></author><category term="ML" /><summary type="html">Today was the first day of attending a term-long project with Data Society UNSW, in collaboration with IBM. The lecturer from Dr. Saeed Kasmani, a Senior AI engineer from IBM presented the fundamentals of data science workflow. The main premise is that throughout the term, we will try to optimize a machine learning algorithm with a dataset. During the term, an IBM machine learning engineer will teach us the fundamentals of machine learning, including data preprocessing and learning algorithms.</summary></entry><entry><title type="html">Hierarchical Clustering: Intuition and Types</title><link href="http://localhost:4000/ml/clustering/" rel="alternate" type="text/html" title="Hierarchical Clustering: Intuition and Types" /><published>2024-05-24T00:00:00+10:00</published><updated>2024-05-24T00:00:00+10:00</updated><id>http://localhost:4000/ml/clustering</id><content type="html" xml:base="http://localhost:4000/ml/clustering/">&lt;p&gt;Today I faced a bit of a problem on my IBM UNSW data science problem, I have the feature “project_description” which includes a range of inputs ranging from “FACADE/ROOFS” to “FY16 RESO A IP SURVEILLANCE CAMERA INSTALLATION”. I recently used a automated labelling method for another feature, but this seem too big of a task for this feature. After researching for a bit I’v found another possible solution “Clustering”! So today I want to share a little overview about clustering, all information is from “Data and Knowledge Modeling and Analysis” via University of waterloo.&lt;/p&gt;

&lt;h1 id=&quot;what-is-clustering&quot;&gt;What is clustering?&lt;/h1&gt;

&lt;p&gt;It is form of unsupervised learning, which means there is nothing we a trying to predict or classify, rather we are trying to put samples together based on similarity, therefore our data is unlabeled. What does this really mean? In supervised learning our client our label feature “we are trying to predict project failure”, but in unlablled data they still give use an objective, but there is not specific feature why are trying to predict or classify using.&lt;/p&gt;

&lt;p&gt;So in a sense we are trying to find inherent structure of the date, even though it may not entirely exist!&lt;/p&gt;

&lt;p&gt;Definition of clustering : group of instances based on similarity and disimilarity.&lt;/p&gt;

&lt;p&gt;Regularly, clustering is used for market segmentation, that is given a set of data, form groups on with inherent characteristic (features) so that was can maximise return on advertisement.&lt;/p&gt;

&lt;h1 id=&quot;types-of-clustering-algorithms&quot;&gt;Types of clustering algorithms&lt;/h1&gt;

&lt;p&gt;There are four main types of clustering approaches:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;Hierarchical Approach&lt;/li&gt;
  &lt;li&gt;Partitioning Approach&lt;/li&gt;
  &lt;li&gt;Density based approach&lt;/li&gt;
  &lt;li&gt;others - NN, Kernal, Affinity Prop&lt;/li&gt;
&lt;/ol&gt;

&lt;h1 id=&quot;should-i-perform-clustering-on-cleaned-data-or-do-some-transformations&quot;&gt;Should I perform clustering on cleaned data or do some transformations?&lt;/h1&gt;

&lt;p&gt;Clustering can be performed directly on cleaned data, but also can be performed AFTER a dimention reduction algorithm is performed, like PCA. Majority of the times this usually leads to better reduced , since reducing dimentionality reduce non-importanly features and vairacne thus present a more accurate manifold/hyper-plane of the data.&lt;/p&gt;

&lt;h1 id=&quot;does-clustering-requres-a-training-pahse-like-supervised-learning&quot;&gt;Does Clustering requres a training pahse like supervised learning?&lt;/h1&gt;

&lt;p&gt;Since we are not trying to predict/classify our goals now is to organise data into groups thus we dont split our datase but rather trying to optimsie division of data with respect to an optimsiation criteria, we choose.&lt;/p&gt;

&lt;p&gt;When is clustering performed in a data sciecne pipeline.Permalink&lt;/p&gt;

&lt;p&gt;Clustering is usually perofrmed in the exploratory data anlytics stages&lt;/p&gt;

&lt;p&gt;Questions to ask when doing Clustering AlgorithmPermalink&lt;/p&gt;

&lt;p&gt;Some of the questions we ask priror to starting the clustering algorithm is;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;How do we represent patterns? Do we represent them as sets of points?&lt;/li&gt;
  &lt;li&gt;How we we decided our measure of similarity? Remember in KNN algorithm we use distance in  norm to measure&lt;/li&gt;
  &lt;li&gt;How many cluster to we have? Again similar to KNN we decides the number of neightbour we choose, how do we know this is right?&lt;/li&gt;
  &lt;li&gt;How do we assess the performance of our clusters? Given we cluster a gorup, then how do we evaluate this?&lt;/li&gt;
  &lt;li&gt;How do we interpret the results?&lt;/li&gt;
&lt;/ol&gt;

&lt;h1 id=&quot;measuring-similarity-for-clustering&quot;&gt;Measuring Similarity for Clustering&lt;/h1&gt;

&lt;p&gt;Similar, to KNN our goals is to put points close to each other in a cluster while far apart points in different cluster, but consequently how would we determine 2 cluster if points are close by. In the examples below one ration method woulc be to cluster data points together (right corner), but how would we seperate the the points seperatly even thought they are as close to each other (middle points).&lt;/p&gt;

&lt;p&gt;clustering simialrity&lt;/p&gt;

&lt;h1 id=&quot;hierarchical-algorithms&quot;&gt;Hierarchical Algorithms&lt;/h1&gt;

&lt;p&gt;This methods entails building a “hierarchy” of cluster. Generally, “hierarchy” means to order somethings from highest to lower or from lowest to highest. There are two types of&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Agglomerative - lowest to highest; start with a bunch of cluster then move to one cluster using a optimization criteria&lt;/li&gt;
  &lt;li&gt;Divisive - highest to lowest; start with 1 cluster then divide into multiple cluster using optimization criteria&lt;/li&gt;
&lt;/ol&gt;

&lt;h1 id=&quot;visualising-the-problem&quot;&gt;Visualising the problem&lt;/h1&gt;
&lt;p&gt;Lets use an simple example, say we want given a client comes to use with customer information. The client ask’s ‘find customer segments for us to create a targeted a marketing strategy’. Now we are given only two features ‘Age’ of customer and ‘Annual Spending’. So the first step is to visualise the two groups.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/clustering/visualise-problem.png&quot; alt=&quot;visualise-cluster&quot; /&gt;&lt;/p&gt;

&lt;p&gt;As you can see we only have 8 data-points in this case. Now we that maybe the best approach would be to cluster into maybe 4 clusters,&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/clustering/human-intuition-clustering-example.png&quot; alt=&quot;human-intution-clustering&quot; /&gt;&lt;/p&gt;

&lt;p&gt;How would a computer do this?&lt;/p&gt;

&lt;h1 id=&quot;agglomerative-hierarchical-algorithmspermalink&quot;&gt;Agglomerative Hierarchical AlgorithmsPermalink&lt;/h1&gt;

&lt;p&gt;Generally Agglomerative Hierarchical Algorithms are cateogrised in to these cateogries,&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/clustering/aggol-cats.png&quot; alt=&quot;aggol-cateogries&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Down up approach, so in we start with finding the closest points in to a given to each point and then make each its own cluster, in this case it would be out human intuition,&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/clustering/human-intuition-clustering-example.png&quot; alt=&quot;human-intution-clustering&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Although in this case this may be the best number of cluster, in reality this may not be the case. Since all points are in a cluster we next try to find minimum distance to each neighbouring cluster. In this case the purple cluster is clostes to the botton on the green cluster is&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/clustering/best-point-three-cluster-aggol.png&quot; alt=&quot;closest-pnt-cluster&quot; /&gt;&lt;/p&gt;

&lt;p&gt;and then join these clusters, so,&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/clustering/three-cluster-algglomerative.png&quot; alt=&quot;three-clusters-agglomerative&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Then we calculate each pnts distance inside the blue cluster to each pnt to other clusters. That is for say a given point in the purple cluster,&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/clustering/finding-distances-three-cluster-agglomerative.png&quot; alt=&quot;distance-one-point-three-clusters-agglomerative&quot; /&gt;&lt;/p&gt;

&lt;p&gt;So this is done another 4 times this case in the purple cluster and then we find the mimum distance between a datapoint in purple to another cluster that is in this case,&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/clustering/best-point-three-cluster-aggol.png&quot; alt=&quot;min-dist-point-three-clusters-agglomerative&quot; /&gt;&lt;/p&gt;

&lt;p&gt;And so we combine these two clusters,&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/clustering/two-clusters-aggol.png&quot; alt=&quot;two-clusters-agglomerative&quot; /&gt;&lt;/p&gt;

&lt;p&gt;This continues until we finally have one cluster, that is all points are in the same cluster, which is where we initially started!&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/clustering/one-cluster-aggol.png&quot; alt=&quot;one-clusters-agglomerative&quot; /&gt;&lt;/p&gt;

&lt;h1 id=&quot;how-to-effectivley-visualise-this-our-different-opottions-for-clusters&quot;&gt;How to effectivley visualise this our different opottions for clusters?&lt;/h1&gt;

&lt;p&gt;In most cases we dealing with multidimentional features space, so visualising it impossible unless we do some dimension reductionality technique like PCA etc. So the most effective way to visualise thses different potential cluster is through tree-diagrams, althought there are other methods including banner, point representation, etc. There are two main types of tree diagrams used in clustering representation dendrograms and n-tree.&lt;/p&gt;

&lt;h1 id=&quot;dendrograms&quot;&gt;Dendrograms&lt;/h1&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/clustering/dendogram-aggol.png&quot; alt=&quot;dendogram-aggol-clustering&quot; /&gt;&lt;/p&gt;

&lt;p&gt;So in the for a agglomerative hierarchical algorithms we start at the bottom and compute, even thought we compute the distance between each point and all other points, we only graph the closest point in the dendrograms. In this case, point 3 was clostes to point 8 with distance of 0.07, while for point 4 closest point was point 6.&lt;/p&gt;

&lt;p&gt;Importantly, for point 1 the clostes point was point 4 (not shown in graph), so bacuase of this it form 1 big cluster with point 1, 4, 6 rather then point 4 only since point 4 clostes point isn’t 1 but 6.&lt;/p&gt;

&lt;h1 id=&quot;n-tree&quot;&gt;n-tree&lt;/h1&gt;
&lt;p&gt;Below, internal nodes are clusters (A,B,C) whilst the terminal notes/leaves are the data points.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/clustering/n-tree-diagram.png&quot; alt=&quot;n-tree-diagram&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Importantly a dendrograms is a type of n-tree, which all internal notes satisify, 
\(\begin{align*}
h(A) \leq h(C) \Longleftrightarrow A \subseteq C
\end{align*}\) 
where h: height on n-tree. And A and C a clusters. Intutivley clearly on our 5-tree diagram h(A) less then h(C) this makes sense we reber back to the n-tree diagram clearly if were were to draw clusters then C takes all points  to , but Cluster A only contains  to  a subset of elements and C. So&lt;/p&gt;

&lt;h1 id=&quot;divisive-hierarchical-clustering&quot;&gt;Divisive Hierarchical Clustering&lt;/h1&gt;

&lt;p&gt;In this instance we want to do the opposite of of agglomerative clustering where we start we one large cluster an&lt;/p&gt;</content><author><name>Shahid Hussain</name><email>shahid.hussain0120@gmail.com</email></author><category term="ML" /><summary type="html">Today I faced a bit of a problem on my IBM UNSW data science problem, I have the feature “project_description” which includes a range of inputs ranging from “FACADE/ROOFS” to “FY16 RESO A IP SURVEILLANCE CAMERA INSTALLATION”. I recently used a automated labelling method for another feature, but this seem too big of a task for this feature. After researching for a bit I’v found another possible solution “Clustering”! So today I want to share a little overview about clustering, all information is from “Data and Knowledge Modeling and Analysis” via University of waterloo.</summary></entry><entry><title type="html">Bayesian statistics vs frequentist statistics : Estimating Probability From Data</title><link href="http://localhost:4000/ml/Estimate-Probability-from-data/" rel="alternate" type="text/html" title="Bayesian statistics vs frequentist statistics : Estimating Probability From Data" /><published>2024-05-21T00:00:00+10:00</published><updated>2024-05-21T00:00:00+10:00</updated><id>http://localhost:4000/ml/Estimate-Probability-from-data</id><content type="html" xml:base="http://localhost:4000/ml/Estimate-Probability-from-data/">&lt;p&gt;Today I was watching Kilian Weinberger lecture on Estimating Probabilities from Data: Maximum Likelihood Estimation” Cornell CS4780 SP17 and now I finally understand the difference between the types of statistics (Also I read “Probabilistic Machine Learning: An Introduction” by Kevin Murphy). The following post will discuss the difference between the two most common schools of statistics, through the lens of machine learning, data estimation using probaiblity; MLE and MAP.&lt;/p&gt;

&lt;h1 id=&quot;recall&quot;&gt;Recall&lt;/h1&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;An important part of why machine can learning is that we assume that all samples points taken are from the same distribution, $ (x_i, y_i) ~ P, \forall i \in \mathbb{Z}^{+} $ and are i.i.d. Now using this assumption which is the backbone of all learning algorithms, then there $ \exists P(x,y) $, for which a conditional expectation can also be calculated, $ P(y&lt;/td&gt;
      &lt;td&gt;x) $, that is, given a feature what the the probability that it lands on this specific label. Alternatively , $ P(x&lt;/td&gt;
      &lt;td&gt;y) $ must also exist, that is given a label what is the probability that it displays certain features. The study of both conditional probabilities are separated using Bayes Theorem,&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

\[\begin{align*}
    P(x | y) &amp;amp;\propto P(y | x)P(x) \quad\quad\text{Discriminative Learning} \\ 
    P(y | x) &amp;amp;\propto P(x | y)P(y) \quad\quad\text{Generative Learning}
\end{align*}\]

&lt;p&gt;In essence, discriminative learning aims to create explicit boundaries between classes of labels, similar to SVMs, Perceptron, and k-NN. On the other hand, generative learning tries to model the distribution of individual classes, such as Naive Bayes or Gaussian Mixture Models (GMM). Within each of these types of learning, you can have parametric models, where we assume the distribution of ( p(x,y) ) comes from a certain well-known distribution like normal, Bernoulli, exponential, or non-parametric.&lt;/p&gt;

&lt;h1 id=&quot;what-is-a-parameter&quot;&gt;What is a parameter?&lt;/h1&gt;
&lt;p&gt;given some distribution a parameter is a point estimate that characteristics a known class of distribution. I’m sure you have heard of common well know distribution including $N(\mu, \sigma^2)$ or $ \mathrm{Bern}(\lambda)$. In this case $\theta$, our parameter can be a set, or singular point estimate which character our distribution so $\theta = (\sigma^2, \mu)$ or $\theta = (\lambda) $&lt;/p&gt;

&lt;h1 id=&quot;motivating-example&quot;&gt;Motivating example&lt;/h1&gt;

&lt;p&gt;For a motivating exmaples consdier flipped a equally wieghted coin. Say we coin and we get \(D = \{ T , T, T, H, H, H, H, T, T, T, T \}\). Now considering it is eually wieghted coin we would hope that our probbilities of getting each side of the dice as \(\frac{1}{2}\) something from pervious years we have come to know. Say we want to know what is the probaiblites of getting a head, then the most intuitive method would be to&lt;/p&gt;

\[\begin{equation*}
    P(\text{getting heads}) = \frac{n_h}{n_t + n_h}
\end{equation*}\]

&lt;p&gt;where $ \text{n} = \text{Number of times gotten a side}$ . Yet it used this equation for our set of outcomes $ D $, we find $ P(\text{heads}) = \frac{4}{11} $, which isn’t 50 \% as we expected. Why is that did we not find the right probability?&lt;/p&gt;

&lt;h1 id=&quot;frequentist-vs-bayesian-n-perspective&quot;&gt;Frequentist vs Bayesian n Perspective&lt;/h1&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;When studying probability theory, we are concerned with $ p(D&lt;/td&gt;
      &lt;td&gt;\theta) $, which models the distribution with some known $ \theta $. On the other hand, in statistics, previously known as inverse probability theory, we are given some data, and we aim to infer the unknown parameters $ \theta $ given observations, $ p(\theta&lt;/td&gt;
      &lt;td&gt;D) $.&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Generally, Frequentist are concerned with ‘frequency’, meaning that over time, the asymptotic behavior of our probability will converge to a certain number, as in the example above. Importantly, this requires a lot of data; otherwise, we would be overfitting. On the other hand, Bayesian statisticians know that data is readily available, and indeed, we have some assumptions we know about the data. Thus, they assume some ‘prior’ distribution of $p(\theta)$ from expertise, enabling them to readily use it when a small sample size is available.&lt;/p&gt;

&lt;h1 id=&quot;frequentist-mle&quot;&gt;Frequentist: MLE&lt;/h1&gt;

&lt;p&gt;So, we define&lt;/p&gt;

\[\begin{align*}
p(\mathcal{D}|\theta) = \prod_{n=1}^N p(y_n|x_n, \theta)
\end{align*}\]

&lt;p&gt;that is our i.i.d assumption of machine learning. Then applying a log (we use to simply computation), we get the log-likelihood,&lt;/p&gt;

\[\begin{align*}
\mathcal{L}(\theta) = \sum_{n=1}^N log( p(y_n|x_n, \theta)).
\end{align*}\]

&lt;p&gt;So, then we define MLE of a parameter&lt;/p&gt;

\[\hat{\theta}_{MLE} = \arg\max_{\theta} \sum_{n=1}^N \log p(y_n | x_n, \theta)\]

&lt;p&gt;So optimisations theory is easier, to optimise a function through minimize cost functions so,&lt;/p&gt;

\[\theta_{\text{MLE}}^{\hat{}} = \arg\max_{\theta} - \sum_{n=1}^N \log p(y_n | x_n, \theta)\]

&lt;h1 id=&quot;mle-example&quot;&gt;MLE example&lt;/h1&gt;
&lt;p&gt;Going back to our examples we flips coins, we now can assume that $p(x,y) ~ Bern(\lambda) $, where now $\theta = P(Y = 1) $, where $Y = number of times of getting heads heads$&lt;/p&gt;

&lt;p&gt;So,&lt;/p&gt;

\[\begin{align*}
    \mathcal{L}(\theta) = \arg\max_{\theta} - \left( \sum_{n=1}^N \mathbb{1}_{y_n=1} \log(\theta) + \mathbb{1}_{y_n=0} \log(1 - \theta) \right).
\end{align*}\]

&lt;p&gt;Let, $ N1 = \sum_{n=1}^N \mathbb{1}&lt;em&gt;{y_n=1}$ and $ N0 =  sum&lt;/em&gt;{n=1}^N \mathbb{1}&lt;em&gt;{y_n=0} $. Now, we can use differentiating and let the loss function equal 0 to find the minimum (like in high school finding the minimum point of a function) to find $\hat{\theta}&lt;/em&gt;{MLE}$,&lt;/p&gt;

\[\begin{align*}
    \hat{\theta}_{MLE}= \frac{N1}{N0 + N1}
\end{align*}\]

&lt;p&gt;Isn’t this similar to our intuition right? This is known as classical statistics, or Frequentist statistics. Importantly we done assume  $\theta$ has any distribution itself but rather is a parameter which contains information about the distribution of a data points.&lt;/p&gt;

&lt;h1 id=&quot;what-is-we-didnt-get-any-heads-in-out-sample&quot;&gt;What is we didnt get any heads in out sample?&lt;/h1&gt;
&lt;p&gt;he $ \hat{\theta}_{MLE} = 0 $. Is this correct? Well, of course not. We know from our intuition it should be $ \frac{1}{2} $. So Frequentists use this method, knowing we (plus one) Laplace Smoothing to ensure in the case of our sample not having an event occurring,&lt;/p&gt;

\[\begin{equation*}
\hat{\theta}_{MLE}= \frac{N1 + 1 }{N0 + N1 + 2}
\end{equation*}\]

&lt;p&gt;Since there is only two classes in our examples head or tails so we add 2 in the denominator.&lt;/p&gt;

&lt;h1 id=&quot;map&quot;&gt;MAP&lt;/h1&gt;
&lt;p&gt;Alternatively in Bayesian statistics we don’t consider Laplace smoothing or $\theta$ as just a parameter but rather in build upon the notion that we don’t have allot of data and data can’t always model the distribution of the sample accurately. So we make this assumption (adding bias) that $ \theta $ random variable. Now a random variable is neither a variables or random but rather a function which maps points of a measurable set $ \sigma$-algebra to the real number line, but a important property is that random variables can have distributions. So, now we can express to new equations, using Bayes Theorem,&lt;/p&gt;

\[\begin{align*}
P(\theta | D) &amp;amp;= \frac{P(D | \theta) P(\theta)}{ P(D)} \Rightarrow \\ 
P(\theta | D) &amp;amp;\quad\propto\quad P(D | \theta) P(\theta). \\ 
\end{align*}\]

&lt;p&gt;Now in Bayesian Statistics, each component is named,&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;
    &lt;table&gt;
      &lt;tbody&gt;
        &lt;tr&gt;
          &lt;td&gt;$ P(D&lt;/td&gt;
          &lt;td&gt;\theta) $ Likelihood of data given ( \theta )&lt;/td&gt;
        &lt;/tr&gt;
      &lt;/tbody&gt;
    &lt;/table&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;table&gt;
      &lt;tbody&gt;
        &lt;tr&gt;
          &lt;td&gt;$ P(\theta&lt;/td&gt;
          &lt;td&gt;D)$ (posterior distribution): Distribution over the parameter(s) ( \theta ) after we have observed the data&lt;/td&gt;
        &lt;/tr&gt;
      &lt;/tbody&gt;
    &lt;/table&gt;
  &lt;/li&gt;
  &lt;li&gt;$P(\theta) $ (prior): Distribution over the parameter(s) ( \theta ) before we see any data. 
We need to choose the prior distribution using our expertise and knowledge which of course can work out great, or horribly wrong if we assume the distribution of our prior wrong. So now,&lt;/li&gt;
&lt;/ul&gt;

\[\begin{align*}
     p(\mathcal{D}|\theta) &amp;amp;= \prod_{n=1}^N p(y_n|x_n, \theta)p(\theta) \\
\end{align*}\]

&lt;p&gt;Applying log,&lt;/p&gt;

\[\begin{align*}
    \mathcal{L}(\theta)&amp;amp;= \sum_{n=1}^N log(p(y_n|x_n, \theta))+ \sum_{n=1}^N log( p(\theta)) \\
\end{align*}\]

&lt;p&gt;So,&lt;/p&gt;

\[\begin{align*}
    \hat{\theta}_{map} = \arg\max_{\theta} \mathcal{L}(\theta)
\end{align*}\]

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Going back to the coin flip we can assume our prior distribution (guess) is $  p(\theta) = Beta(\theta&lt;/td&gt;
      &lt;td&gt;a, b) $ then our log likelihood ends up becoming&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

\[\begin{align*}
    \mathcal{L}(\theta) = &amp;amp;\left( \sum_{n=1}^N \mathbb{1}_{y_n=1} \log(\theta) + \mathbb{1}_{y_n=0} \log(1 - \theta) \right) + [(a - 1)log(\theta) + (b - 1)log(1 - \theta)]
\end{align*}\]

&lt;p&gt;Then using normal minimisation method of finding first derivative letting it equal to zero to find minimizer for $\hat{\theta})$ we get&lt;/p&gt;

\[\begin{align*}
    \hat{\theta}_{map} = \frac{N1 + a - 1}{N1 + N0 + a + b - 2}
\end{align*}\]

&lt;p&gt;So by assuming a prior distribution in Bayesian statistics we end up getting a very similar estimator found in Frequentist statistics using Laplace Smoothing. So in a sense they are very similar!&lt;/p&gt;</content><author><name>Shahid Hussain</name><email>shahid.hussain0120@gmail.com</email></author><category term="ML" /><summary type="html">Today I was watching Kilian Weinberger lecture on Estimating Probabilities from Data: Maximum Likelihood Estimation” Cornell CS4780 SP17 and now I finally understand the difference between the types of statistics (Also I read “Probabilistic Machine Learning: An Introduction” by Kevin Murphy). The following post will discuss the difference between the two most common schools of statistics, through the lens of machine learning, data estimation using probaiblity; MLE and MAP.</summary></entry><entry><title type="html">How sampling distribution is the link between Machine Learning and data science</title><link href="http://localhost:4000/random/distribution-link-datascience-ml/" rel="alternate" type="text/html" title="How sampling distribution is the link between Machine Learning and data science" /><published>2024-05-18T00:00:00+10:00</published><updated>2024-05-18T00:00:00+10:00</updated><id>http://localhost:4000/random/distribution-link-datascience-ml</id><content type="html" xml:base="http://localhost:4000/random/distribution-link-datascience-ml/">&lt;h1 id=&quot;ever-wondered-how-these-two-field-like-with-concrete-examples&quot;&gt;Ever wondered how these two field like with concrete examples?&lt;/h1&gt;
&lt;p&gt;Data science formull is defined “statistics, scientific computing, scientific methods, processes, algorithms and systems to extract or extrapolate knowledge and insights from potentially noisy, structured, or unstructured data”. In a informal sense we are trying to transform raw data into strucutre data for a specific task. Now this take can range from mere simple data analysis to more complex task including classifying data or regression problems. Now, one role of data sciecne is to provide data to machine learning engineers for a spcifci learning problem.  So the next question begins ‘what does the macvhien learnign requires from a data scientist to ensrue data is correct?’. We will look at the basics of machine learning algorithsm, including loss functions, assumptions and then devlve into the importance of data quality given by data scientist.&lt;/p&gt;

&lt;h1 id=&quot;little-about-machine-learning&quot;&gt;Little about machine learning&lt;/h1&gt;
&lt;p&gt;Machine learning is a process where by a machine, usually a program, learns from given data where by we have input, \(X\) and output \(Y\), known as feature inputs and labels, respectively. Now the goals is to create a program which can adequatly be able to given predict ‘label’ given a new input. An exmaples can be classify females and males, know a data scientist will go out and take picture of males and females, and then label them both males or female, then this is given to a machine leanring program for which is looks at data and tries to understand distinction bewteen male and females, untill it get very good at it. Then we will given it new picture and then hopefully it will be able to identify correctly geneder of the male or female.&lt;/p&gt;

&lt;h1 id=&quot;now-an-important-assumptio-we-make-is-machine-learning-is-that-all-samples-take-have-the-same-distribtion-p-and-are-iid-why&quot;&gt;Now an important assumptio we make is Machine learning is that all samples take have the same distribtion \(P\) and are i.i.d why?&lt;/h1&gt;

&lt;p&gt;This creates the link between machien learning and data sciecne. Ifall possible data that we can be given is from the same distribition, since if they it would be impossible to predict or classify random selected people since we a any random input.&lt;/p&gt;

&lt;h2 id=&quot;example--gender-shades-project-2018&quot;&gt;Example : Gender Shades project 2018&lt;/h2&gt;

&lt;p&gt;In 2018 gender classification algorithms developed by IBM and Microsoft was studye based on miclassification based upon skin tone, from four cateogires: darker-skinned females, darker-skinned males, lighter-skinned females, and lighter-skinned males. All three algorithms performed the worst on darker-skinned females, with error rates up to 34% higher than for lighter-skinned males.&lt;/p&gt;

&lt;p&gt;A key reaosn might be the samples distribution, now say the task to recognise face, if a data scientist provides face of only light-skinned males then cleary the algorithsm will only be able to identify these indviduals and fall short on other skins tones. So the distribution we wrong for the task since the data that the algorith was trained was different to the actually dsitirbution it was testet on&lt;/p&gt;

&lt;h1 id=&quot;continying&quot;&gt;Continying&lt;/h1&gt;
&lt;p&gt;Additionaly, these samples must be i.i.d, so we have already adressed the identifcallty distribution, but indepecne is importance is to ensure that these samples done effect one another cause if they do it would be impossible to find the relationship between two samples (x_i, y_i)&lt;/p&gt;

&lt;h1 id=&quot;how-a-machine-algorithm-works-using-out-asusmption&quot;&gt;How a Machine algorithm works using out asusmption&lt;/h1&gt;

&lt;p&gt;So currently I’ve talked about the assumption that all possible data that an algorithsm will very see is given by data sciecntist so the roels of trhe data sciecne to provides data which will represent all possible data it will be given in the future.&lt;/p&gt;

&lt;h1 id=&quot;how-then-does-a-machine-learning-engineer-optimise-this-data&quot;&gt;How then does a Machine learning engineer optimise this data?&lt;/h1&gt;
&lt;p&gt;(add picture)
so out goals to minimise the error rates of our algorithm chosen h, we do this through choose a loss function which is appropriate to the task, now importantly iv talked about teh improtance of the algorithm bening able to generalise to any data set and that the data, of course  is assumpted to from the same distribution \(P\). Our easier first guess is for out loos function&lt;/p&gt;

&lt;p&gt;l(h;D)&lt;/p&gt;

&lt;p&gt;but the key problem is that this only optimsised out dataset in a sense it memories out data givne but give new sample it would not be able to rpedict it well, so we must create a denfition which generlaise well for all possible data from a asusmed distirbution 
\(E(l(X,Y))_{(x_i,y_i) ~ P}\)
That is we want to find the middle weight of all possible samples from data future and past&lt;/p&gt;

&lt;h1 id=&quot;how-we-we-implement-this-into-our-machine-leanring-program&quot;&gt;How we we implement this into our machine leanring program?&lt;/h1&gt;

&lt;p&gt;This is why we split data into test and training set, for the sole reason is that out assumption is all points are (xi,yi) ~ P so we act like our data is a represnetaiotn of the whole population of task we need to learn and for that reason we only touch our test set for final evaluation process. we it would givne use a interpretation of how well&lt;/p&gt;

&lt;h1 id=&quot;conlusion&quot;&gt;Conlusion&lt;/h1&gt;
&lt;p&gt;So the reaosn why data sciecne is importacne of machine learning engineers is that since machine leanirng engineeers assume that all data for a learnign as has the same distribution, the data scienctist roles is to ensure that the data they provides represent all possible inputs for that task.&lt;/p&gt;</content><author><name>Shahid Hussain</name><email>shahid.hussain0120@gmail.com</email></author><category term="Random" /><summary type="html">Ever wondered how these two field like with concrete examples? Data science formull is defined “statistics, scientific computing, scientific methods, processes, algorithms and systems to extract or extrapolate knowledge and insights from potentially noisy, structured, or unstructured data”. In a informal sense we are trying to transform raw data into strucutre data for a specific task. Now this take can range from mere simple data analysis to more complex task including classifying data or regression problems. Now, one role of data sciecne is to provide data to machine learning engineers for a spcifci learning problem. So the next question begins ‘what does the macvhien learnign requires from a data scientist to ensrue data is correct?’. We will look at the basics of machine learning algorithsm, including loss functions, assumptions and then devlve into the importance of data quality given by data scientist.</summary></entry><entry><title type="html">How I went from 40 WPM to 100 WPM in 3 months without trying!</title><link href="http://localhost:4000/random/improving-typing-speed/" rel="alternate" type="text/html" title="How I went from 40 WPM to 100 WPM in 3 months without trying!" /><published>2024-05-17T00:00:00+10:00</published><updated>2024-05-17T00:00:00+10:00</updated><id>http://localhost:4000/random/improving-typing-speed</id><content type="html" xml:base="http://localhost:4000/random/improving-typing-speed/">&lt;p&gt;Flashbacks to high school when all my friends used to engage in typing test battles; touch typing, speed, the whole shebang. Then there was me, trying to look at the keyboard, using two fingers from each hand, and managing a grand total of 40 WPM. HUMPH.&lt;/p&gt;

&lt;p&gt;Recently, I’ve begun to understand the importance of being able to type fast and its perks. Not only does it help with completing computer tasks faster, but as technology natives, it’s almost a necessity. More importantly, I believe in having mastery over all parts of my body! I feel there’s some hidden neurological benefits in being able to control your fingers eloquently; it helps in learning other skills faster. From my observations, people who type fast usually pick up instruments a lot quicker compared to myself; trying to learn guitar was extremely difficult!&lt;/p&gt;

&lt;p&gt;Here’s a quick rundown of how I improved my typing speed without really following any formal tutorials:&lt;/p&gt;

&lt;h1 id=&quot;tip-1-passive-learning-using-monkeytype&quot;&gt;Tip 1: Passive learning using MonkeyType&lt;/h1&gt;
&lt;p&gt;Practice until mastery. I pretty much just spammed 25-second MonkeyType tests; it’s so easy and doesn’t take much time. Every time you’re about to start a new task, just hop on and smash out a test. Not only does Huberman always say we learn best if we stop thinking for like 10-15 seconds, but it’s also kinda fun trying to beat a previous score like it’s a video game. (I’ve done 400 test already! )&lt;/p&gt;

&lt;h1 id=&quot;tip-2-start-from-basics-using-at-least-four-fingers&quot;&gt;Tip 2: Start from basics, using at least four fingers!&lt;/h1&gt;

&lt;p&gt;Yeah, this is a tough one, but if you’re currently only using two fingers, you have to move to using four fingers; your learning curve will be exponential. In the beginning, it will be difficult, but as you get used to it, the rate of learning will be insane!&lt;/p&gt;

&lt;h1 id=&quot;tip-3-dont-look-at-the-keyboard&quot;&gt;Tip 3: Don’t look at the keyboard&lt;/h1&gt;

&lt;p&gt;As computer natives, even though we think we don’t know where the keys are, we subconsciously already know where all the letters are on the keyboard; we just need to practice a little!&lt;/p&gt;

&lt;p&gt;It’s as simple as that!&lt;/p&gt;</content><author><name>Shahid Hussain</name><email>shahid.hussain0120@gmail.com</email></author><category term="Random" /><summary type="html">Flashbacks to high school when all my friends used to engage in typing test battles; touch typing, speed, the whole shebang. Then there was me, trying to look at the keyboard, using two fingers from each hand, and managing a grand total of 40 WPM. HUMPH.</summary></entry><entry><title type="html">Line Search Methods for Numerical Optimisation</title><link href="http://localhost:4000/statistics/Linear-Search-Methods/" rel="alternate" type="text/html" title="Line Search Methods for Numerical Optimisation" /><published>2024-03-30T00:00:00+11:00</published><updated>2024-03-30T00:00:00+11:00</updated><id>http://localhost:4000/statistics/Linear-Search-Methods</id><content type="html" xml:base="http://localhost:4000/statistics/Linear-Search-Methods/">&lt;p&gt;Linear Search Methods are a integral part of numerical optimisation, which is a set of algorithms to solve mathematics programming problems. Importantly, numerical optimisation are solved in two key methods;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Linear search strategy&lt;/li&gt;
  &lt;li&gt;Trust region&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;This blog post will focus on the linear search strategy for optimisation techniques. This blog post requires a basic understanding on optimisation - objective functions, variables and constrained, so lets get into it.&lt;/p&gt;

&lt;h1 id=&quot;what-is-line-search-and-trust-region-how-do-they-differ&quot;&gt;What is line search and trust region, how do they differ?&lt;/h1&gt;

&lt;p&gt;Our main goal with optimsiation is to find a global minimimum points which in real life minimum point which reduced the time, cost etc. Now given we can algebraically find this optimal solution through other optimisation techniques. Let’s see an example,&lt;/p&gt;

\[\begin{align*}
\min_{x \in \mathbb{R}^2} \quad &amp;amp; x^2 - sin(x)\\
\end{align*}\]

&lt;p&gt;Now, if we were to use algebratic methods using First order sufficient condition we find the unconstrained stationary point by $\triangledown f(\mathbf{x}) = \mathbf{0}$. But,&lt;/p&gt;

\[\triangledown f(\mathbf{x}) = \mathbf{0} \Leftrightarrow 2x - cos(x) = 0\]

&lt;p&gt;So the only way to finding a $ x $ algebratically is through guessing possible $ x $ values, even though the solution exists,&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/linear-search/2x.png&quot; alt=&quot;image tooltip here&quot; /&gt;&lt;/p&gt;

&lt;p&gt;So this is where numerical optimsiation comes in. In essense rather then using algebraic methods to solve the optimisation problem we now is iterative process through a starting point $ x^{(0)} $ and then generatign a sequecnes of sets $ x^{(k)} $ which termiantes when a global minimum is reached, $ x^* $. Finding a new iteration step $ x^{(k)} $ is through finding where the rule of function value decreases known as decent methods,&lt;/p&gt;

\[\begin{align*}
f(x^{(k+1)}) &amp;lt; f(x^{(k)})
\end{align*}\]

&lt;p&gt;We denote $ s^{(k)} $ as a search direction, which is is just given a point, $ x^{(k)} $ in which direction we move in? 
so intutively with no restricstion $ s^{(k)} $ can be in all directions from at point $ x^{(k)} $. Now, since restricitions imposed on $ x^{(k)} $ is the decent method how do apply this?&lt;/p&gt;

&lt;p&gt;Definition : At a point $ x^{(k)} $ , a direction $ s^{(k)} $ is a descent direction if&lt;/p&gt;

\[\begin{align*}
\triangledown f(x^{(k)})^T s^{k} &amp;lt; 0 
\end{align*}\]

&lt;p&gt;Why?&lt;/p&gt;

&lt;p&gt;Now $\triangledown f(x) $ points in direction of , so by taking $ - \triangledown f(x) $ we point any $ x $ to direction of steepest descent. So, $ \triangledown f(x^{(k)})^T s^{k} &amp;lt; 0 $.&lt;/p&gt;

&lt;p&gt;So, since we know that $ s_{(k)} $ can be in any direction then to restirict we want all search direction which ensures we are in descent getting closer to minimiser ,&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/linear-search/decent-direction.png&quot; alt=&quot;decent-direciton&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Intitively, we want to next iteration to be $ x^{(k + 1)} $ to be as a know in ferences to out previous iteration,  $ x^{(k)} $, and  $ s^{(k)} $, but since our search direction is also a vector direction we we dont impose a ‘length’ the search direction can be then we can overeach out minimiser $ x^* $&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/linear-search/step-size-overeach.png&quot; alt=&quot;step-size-overeach&quot; /&gt;&lt;/p&gt;

&lt;p&gt;So we impose a step length $ \alpha_{k} $, in most algorithms, we will chose a step-size and after eahc iterations we optimise the step-size inrdoer to find the optimal ‘jump’ we want to impose.&lt;/p&gt;

&lt;p&gt;Therfore by definition $ s^{(k)}$ is in decent direction of  $ x^{(k)} $, if $ f(x^{(k)} + \alpha s^{(k)}) &amp;lt; f(x^{(k)})$ where we define $ x^{(k + 1)} =  x^{(k)} + \alpha s^{(k)} $. Our goals is to prove that this is try using our definition of decent direction.&lt;/p&gt;

&lt;p&gt;Let $ l(\alpha) = f(x^{(k)} + \alpha s^{(k)}) $ then $ \frac{d}{dx}(l(\alpha)) = \frac{d}{dx}f(x^{(k)} + \alpha s^{(k)}) $ when $ x^{(k)} = 0$ then, intuitively, if we can show that $ l’(\alpha) &amp;lt; 0 \Rightarrow l(\alpha) &amp;lt; l(0) \Rightarrow f(x^{(k)} + \alpha s^{(k)}) &amp;lt; f(x^{(k)}) $. Visually, in $\mathbb{R}^2$ for this to hold true then ,&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/linear-search/direction-decent-proof.png&quot; alt=&quot;direction-desecnet-proof&quot; /&gt;&lt;/p&gt;

&lt;p&gt;So, since $ x^{(k)} \in \mathbb{R}^n $ we have to use the chain rule to find  $ \frac{d}{dx}f(x^{(k)} + \alpha s^{(k)}) $. Let $x_{i}(\alpha) = x_{i}^{(k)} + \alpha s_{n}^{(k)}$ for all $ i \in \mathbb{Z^+} $ and for a fixed $ x^{(k)}, s^{(k)} $ we have,&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/linear-search/chain-rule-decent-direciton.png&quot; alt=&quot;chain-rule&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Then applying $ \alpha = 0 \Rightarrow l’(0) = f(x^{(k)})^Ts^{(k)} $. Now given $ s^{(k)} $ is in decent direction then  $ l’(0) = f(x^{(k)})^Ts^{(k)} &amp;lt; 0 $
so hence, $ f(x^{(k)} + \alpha s^{(k)}) &amp;lt; f(x^{(k)}) $&lt;/p&gt;

&lt;h1 id=&quot;how-do-we-ensure-that-we-pick-a-point--xk1--such-that--fxk--alpha-sk--is-closest-to--x-&quot;&gt;How do we ensure that we pick a point $ x^{(k+1)} $ such that $ f(x^{(k)} + \alpha s^{(k)}) $ is closest to $ x^* $?&lt;/h1&gt;
&lt;p&gt;Finally, the process is known line search strategy which by definition is&lt;/p&gt;

\[\begin{align*}
\min_{\alpha \geq 0} \quad &amp;amp; f(x^{(k)} + \alpha s^{(k)})
\end{align*}\]

&lt;p&gt;Importantly, this is known as exact line search since, finds the optimal step size that minimizes the objective function along the search direction. But there exsit different types of line search including Backtracking Line Search, Golden Section Search, interpolation-Based Line Search. All these line search play around with step size, $ \alpha $ to find the most optimal method to minimer objective function.&lt;/p&gt;</content><author><name>Shahid Hussain</name><email>shahid.hussain0120@gmail.com</email></author><category term="Statistics" /><summary type="html">Linear Search Methods are a integral part of numerical optimisation, which is a set of algorithms to solve mathematics programming problems. Importantly, numerical optimisation are solved in two key methods; Linear search strategy Trust region</summary></entry><entry><title type="html">Olympiad Level Counting Made Easy with Jensen’s inequality</title><link href="http://localhost:4000/statistics/Olympaid-Level-Counting/" rel="alternate" type="text/html" title="Olympiad Level Counting Made Easy with Jensen’s inequality" /><published>2024-03-27T00:00:00+11:00</published><updated>2024-03-27T00:00:00+11:00</updated><id>http://localhost:4000/statistics/Olympaid-Level-Counting</id><content type="html" xml:base="http://localhost:4000/statistics/Olympaid-Level-Counting/">&lt;p&gt;Have you every wondered how high school students with no formal higher level of mathematical knowledge are able to solve complex questions like this? Prove that&lt;/p&gt;

\[\frac{1}{x-1}+ \frac{1}{x} + \frac{1}{x+1} \geq \frac{3}{x},\quad x &amp;gt; 1.\]

&lt;p&gt;Or&lt;/p&gt;

\[(1 + \frac{1}{x})(1 + \frac{1}{y})(1 + \frac{1}{z}) \geq 64.\]

&lt;p&gt;Many of you have no idea how some 14 year old kid is able to solve these questions, yet at my final year of university, I am still not able to intuitively solve these. I believe that this is true for most university students.&lt;/p&gt;

&lt;p&gt;Now, of course, the most rational method would be trying to move all the variables to one side, then try estimating the values for which the right-hand side equals the left-hand side. Then, the exam hits you with give me exact values for \(x,y,z\) and now you are stumped with this 1 hour exam and  you’ll just about spend most of your time guessing possible values. Here comes the bang, Olympiad contestants in my eyes now are of course genius, but they know a set of specialised tools in their tool bag of which they select the appropriate tool for the job. Now, selecting a the right tool can be difficult (Mathematics tool bags a very,very deep).&lt;/p&gt;

&lt;h2 id=&quot;one-of-the-most-powerful-tools-in-the-mathematics-tool-bag--jensens-inequality&quot;&gt;One of the most powerful tools in the mathematics tool bag : Jensen’s Inequality.&lt;/h2&gt;
&lt;p&gt;For any convex function \(h\), we have,&lt;/p&gt;

\[\mathbb{E}h(Y) \geq h(\mathbb{E}Y)\]

&lt;p&gt;How did we get to conclusion of the great ‘power’ of Jensen’s Inequality? According to my professor, Dr.Zdravko Botev, power comes from two key characteristics (1) simplicity (2) usefulness. Not only is Jensen Inequality applicable in a range of context, including counting as above, but also real analysis, probability, economics, statistics, and machine learning, but it’s proof that it is so simple.&lt;/p&gt;

&lt;p&gt;\(\textit{Proof.}\) From the definition of convexity, we have for x and all Y:&lt;/p&gt;

\[h(Y) \geq h(x) + v^T(Y-x)\]

&lt;p&gt;By the monotonicty and linearity of expectation, we have&lt;/p&gt;

\[\mathbb{E}h(Y) \geq h(x) + v^T\mathbb{E}(Y-x)\]

&lt;p&gt;Now, since this is true for each \(x\) we can chose \(x = \mathbb{E}(Y)\). So,&lt;/p&gt;

\[\mathbb{E}h(Y) \geq h(\mathbb{E}Y) + v^T\mathbb{E}(Y-\mathbb{E}Y) \Rightarrow  \mathbb{E}h(Y) \geq h(\mathbb{E}Y).\]

&lt;p&gt;Which is Jensen’s Inequality.&lt;/p&gt;

&lt;h2 id=&quot;now-how-do-we-apply-this-powerful-tool-to-our-counting-problem&quot;&gt;Now, how do we apply this powerful tool to our counting problem?&lt;/h2&gt;
&lt;p&gt;The idea is that we want to find a convex function which applies to the problem and hence we can use Jensen’s Inequality. So, for:&lt;/p&gt;

\[\frac{1}{x-1}+ \frac{1}{x} + \frac{1}{x+1} \geq \frac{3}{x},\quad x &amp;gt; 1.\]

&lt;p&gt;We can try \(h(x) = \frac{1}{x}\) or \(h(x) = \frac{1}{x + 1}\) or \(h(x) = \frac{1}{x - 1}\) and we can confirm that these a convex function by showing  \(h&quot;(x) &amp;gt; 0, \forall x \in \mathbb{R}\). Now, lets try  \(h(x) = \frac{1}{x}, x &amp;gt; 1\).
Now, for a random variables \(Y\) we apply Jensen’s Inequality,&lt;/p&gt;

\[\mathbb{E}[\frac{1}{Y}] \geq \frac{1}{\mathbb{E}Y}\]

&lt;p&gt;Next we consider a distribution for \(Y\). Since, we have 3 fractions a logical choice would be for \(Y\) distribution,&lt;/p&gt;

\[\mathbb{P}(Y = x) = \mathbb{P}(Y = x + 1) = \mathbb{P}(Y = x - 1) = \frac{1}{3}.\]

&lt;p&gt;For this \(Y\), we have a three point distribution, we can compute the expectations and hence Jensen’s inequality,&lt;/p&gt;

\[\begin{align*}
    \mathbb{E}[\frac{1}{Y}] = \frac{1}{3} \times \frac{1}{x} + \frac{1}{3} \times \frac{1}{x - 1} + \frac{1}{3} \times \frac{1}{x + 1}, \\
    \frac{1}{\mathbb{E}Y} = \frac{1}{\frac{1}{3} \times \frac{1}{x} + \frac{1}{3} \times \frac{1}{x - 1} + \frac{1}{3} \times \frac{1}{x + 1}} = \frac{1}{x}.
\end{align*}\]

&lt;p&gt;So,&lt;/p&gt;

\[\begin{align*}
    \mathbb{E}[\frac{1}{Y}] &amp;amp;\geq \frac{1}{\mathbb{E}Y} \Rightarrow \\
    \frac{1}{3}[\frac{1}{x-1} + \frac{1}{x} + \frac{1}{x+1}] &amp;amp;\geq \frac{1}{x} \Rightarrow \\
    \frac{1}{x-1} + \frac{1}{x} + \frac{1}{x+1} &amp;amp;\geq \frac{3}{x}.
\end{align*}\]

&lt;p&gt;Wala! Wasn’t that hard, right? Maybe you can try this one,&lt;/p&gt;

\[(1 + \frac{1}{x})(1 + \frac{1}{y})(1 + \frac{1}{z}) \geq 64.\]

&lt;p&gt;hint: \(h(x) = \text{ln}(1 + \frac{1}{x})\)&lt;/p&gt;</content><author><name>Shahid Hussain</name><email>shahid.hussain0120@gmail.com</email></author><category term="Statistics" /><summary type="html">Have you every wondered how high school students with no formal higher level of mathematical knowledge are able to solve complex questions like this? Prove that</summary></entry><entry><title type="html">Roadmap to Learn Transformers in less then 3 minutes</title><link href="http://localhost:4000/machine%20learning/how-to-learn-transformers/" rel="alternate" type="text/html" title="Roadmap to Learn Transformers in less then 3 minutes" /><published>2024-01-29T00:00:00+11:00</published><updated>2024-01-29T00:00:00+11:00</updated><id>http://localhost:4000/machine%20learning/how-to-learn-transformers</id><content type="html" xml:base="http://localhost:4000/machine%20learning/how-to-learn-transformers/">&lt;p&gt;When I started my journey into machine learning, I remember watching an interview with Andrej Karpathy, a Sr. Director of AI at Tesla, on the Lex Fridman podcast, where he talked about something called a “transformer,” and he described it so profoundly as a new way of computing. In combination, I had learned that ChatGPT, BERT were all powered by transformers and that in order to become a machine learning engineer, you NEEDED to know transformers.&lt;/p&gt;

&lt;p&gt;But upon looking online for a simple roadmap of the topic I needed to cover, I found that most blog posts focus on the individual components you need to know inside a transformer architecture rather than how to get to the point to potentially understand a transformer architecture.&lt;/p&gt;

&lt;p&gt;Definition of Transformer: Machine learning architectures that allow asking multiple questions about an input and receiving answers out of questions from surrounding inputs, which helps us compute an output!&lt;/p&gt;

&lt;h1 id=&quot;so-lets-beging&quot;&gt;So lets beging&lt;/h1&gt;

&lt;h1 id=&quot;1--some-basic-understanding-on-machine-learning&quot;&gt;1 . Some basic understanding on Machine Learning&lt;/h1&gt;

&lt;p&gt;Definition of Machine Learning: process of exploring data using mathematics to create scalable and reusable algorithms in order to make decisions/improve society. Pretty much give an algorithm some data with output or no outputs and hope it can solve new data using this given data.&lt;/p&gt;

&lt;p&gt;Machine Learning is broken down into two parts: Supervised and Unsupervised learning (kinda there are a few subsets of machine learning, but we only need to focus on these)&lt;/p&gt;

&lt;p&gt;Supervised: given we feed the algorithm with pairs of inputs and corresponding outputs. The goal of supervised learning is to feed new inputs and try to figure out an output.&lt;/p&gt;

&lt;p&gt;Unsupervised learning: where you feed the algorithm inputs and outputs, but your goal isn’t to predict new outputs but rather identifying patterns, visualizations, etc.&lt;/p&gt;

&lt;p&gt;I recommend just going through “The Hundred-Page Machine Learning Book” by Andriy Burkov, getting a basic grip of the concepts.&lt;/p&gt;

&lt;p&gt;So a subset of machine learning techniques is deep learning. A part of deep learning is the transformer architecture.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;&apos;../assets/images/roadmap-to-trasnfomers/deep-learbning-machine-learning-picture.png&quot; alt=&quot;Ven Diagram of where transfomers realtionship with Machine Learning&quot; /&gt;&lt;/p&gt;

&lt;h1 id=&quot;deep-learing&quot;&gt;Deep learing&lt;/h1&gt;

&lt;p&gt;Now the main concept you should learn is:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Feedfoward Neural Networks -&amp;gt; Focus!&lt;/li&gt;
  &lt;li&gt;CNN - the basics&lt;/li&gt;
  &lt;li&gt;RNN - learn GRU’s and LSTM’s&lt;/li&gt;
  &lt;li&gt;Attention Architecture&lt;/li&gt;
  &lt;li&gt;Transformers Architecture&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;You should complete these processes in order and ensure you have a strong understanding of feedforward neural networks. I recommend these two resources:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;(Neural Networks and Deep Learning)[http://neuralnetworksanddeeplearning.com]&lt;/li&gt;
  &lt;li&gt;(3blue2brown)[https://www.youtube.com/watch?v=aircAruvnKk&amp;amp;list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi]&lt;/li&gt;
&lt;/ol&gt;

&lt;h1 id=&quot;there-you-go&quot;&gt;There you go!&lt;/h1&gt;</content><author><name>Shahid Hussain</name><email>shahid.hussain0120@gmail.com</email></author><category term="Machine Learning" /><summary type="html">When I started my journey into machine learning, I remember watching an interview with Andrej Karpathy, a Sr. Director of AI at Tesla, on the Lex Fridman podcast, where he talked about something called a “transformer,” and he described it so profoundly as a new way of computing. In combination, I had learned that ChatGPT, BERT were all powered by transformers and that in order to become a machine learning engineer, you NEEDED to know transformers.</summary></entry><entry><title type="html">Functional vs Sequetial API for Keras in less then 3 minutes</title><link href="http://localhost:4000/machine%20learning/functional-sequential-api/" rel="alternate" type="text/html" title="Functional vs Sequetial API for Keras in less then 3 minutes" /><published>2024-01-24T00:00:00+11:00</published><updated>2024-01-24T00:00:00+11:00</updated><id>http://localhost:4000/machine%20learning/functional-sequential-api</id><content type="html" xml:base="http://localhost:4000/machine%20learning/functional-sequential-api/">&lt;p&gt;Reading to Keras/Tensorflow documentation, it’s a little hard to understand what exactly is the difference between sequential and functional API and all other resources are too long to read, so lets simplify it!&lt;/p&gt;

&lt;p&gt;Lets talk visually:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/function_sequential_api/function_sequential_api.png&quot; alt=&quot;function_sequential_api.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The whole point of Tensorflow with Keras is to simply the process of creating neural networks so now we dont spend time on manully coding a neural network, but rather focus on improving the performance of our model. Now how exactly does Functional api improve flexibility but at the cost of complexity?&lt;/p&gt;

&lt;h2 id=&quot;sequential-api&quot;&gt;Sequential API&lt;/h2&gt;
&lt;p&gt;Sequential API’s tipically look like this:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/function_sequential_api/sequential.png&quot; alt=&quot;sequential.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Notice, although we specify the pooling dimensions and strides and other arguements within the tf.keras.layers call , we can’t input specific paramters like Z1,A1 or Z2. Importantly it all happens sequentially so the model will start from the top end go by each call one by one until the end.&lt;/p&gt;

&lt;h1 id=&quot;function-api--spot-the-difference&quot;&gt;Function API : spot the difference&lt;/h1&gt;
&lt;p&gt;Alternatively, comparing this to functional API it allows use to play around with the parameters:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/function_sequential_api/sequential.png&quot; alt=&quot;functional_api.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Notice how we adding paramters to our calls to tf.keras.layers()(Paramter) providing us flexibility to choose which parameters we want to trasnform. Note this is just one way of taking advantage of function API. Other possible options are :&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;Multiple inputs - Now we can have multiple paramters since our functional isnt called linearly&lt;/li&gt;
  &lt;li&gt;Sharing inputs - say we want Z1 to have multiple acitivations say Leaky-RelU and ReLU&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;But as you can see the possibility or errors increases since you can play around with which inputs you want where. So be careful!&lt;/p&gt;

&lt;h1 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h1&gt;

&lt;p&gt;Hopefully now you understand the difference between Sequential and Functional API!&lt;/p&gt;</content><author><name>Shahid Hussain</name><email>shahid.hussain0120@gmail.com</email></author><category term="Machine Learning" /><summary type="html">Reading to Keras/Tensorflow documentation, it’s a little hard to understand what exactly is the difference between sequential and functional API and all other resources are too long to read, so lets simplify it!</summary></entry></feed>